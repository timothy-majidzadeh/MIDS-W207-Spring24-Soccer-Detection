{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "516fede5-9df9-498d-bde0-3cb7b5d78b4e",
   "metadata": {
    "id": "516fede5-9df9-498d-bde0-3cb7b5d78b4e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\timot\\anaconda3\\envs\\tf_2_env\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from sklearn import metrics\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "mids_dir = Path(\"D:\\\\MIDS-W207\")\n",
    "data = mids_dir/\"datasets/soccertrack_square\"\n",
    "project = mids_dir/\"MIDS-W207-Spring24-Soccer-Detection\"\n",
    "analysis = project/\"analysis\"\n",
    "drive_dir = \"/content/drive/MyDrive/School/Graduate/Datasci 207/\"\n",
    "colab_images = \"/content/drive/MyDrive/School/Graduate/Datasci 207/soccertrack_square/\"\n",
    "\n",
    "# Author: Timothy Majidzadeh\n",
    "# Date Created: April 9, 2024\n",
    "# Date Updated: April 17, 2024\n",
    "# Description: Try CNN for classification on the soccertrack_square dataset.\n",
    "# Re-uses some code from T. Majidzadeh's Homework 10 submission for MIDS W207 Spring 2024.\n",
    "# Notes: [v1] Created program.\n",
    "#        [v2] Tried using Google Colab to manage compute resources.\n",
    "# Inputs: Frame-by-frame labels saved as separate text files.\n",
    "# Outputs: A CNN classifier for the soccertrack_square dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "vsM1Zl3G1G2b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vsM1Zl3G1G2b",
    "outputId": "3321ea85-2e51-41c5-d3a6-4cdbdcc6dbb0"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c2a19ff-2707-43ee-8e55-339c9f22c5b3",
   "metadata": {
    "id": "4c2a19ff-2707-43ee-8e55-339c9f22c5b3"
   },
   "outputs": [],
   "source": [
    "# 1. Load the labels data and map to classes.\n",
    "class_dict = {\n",
    "    0: \"No Objects\",\n",
    "    1: \"Team 0 Only\",\n",
    "    2: \"Team 1 Only\",\n",
    "    3: \"Ball Only\",\n",
    "    4: \"Team 0 and Team 1\",\n",
    "    5: \"Team 0 and Ball\",\n",
    "    6: \"Team 1 and Ball\",\n",
    "    7: \"All Classes\"\n",
    "}\n",
    "\n",
    "# Because certain class combinations are rare, it may be more effective to try each class individually.\n",
    "# Remap to a value of 1 if one class is present, 0 otherwise.\n",
    "ball_remap = {\n",
    "    0: 0,\n",
    "    1: 0,\n",
    "    2: 0,\n",
    "    3: 1,\n",
    "    4: 0,\n",
    "    5: 1,\n",
    "    6: 1,\n",
    "    7: 1\n",
    "}\n",
    "\n",
    "team_0_remap = {\n",
    "    0: 0,\n",
    "    1: 1,\n",
    "    2: 0,\n",
    "    3: 0,\n",
    "    4: 1,\n",
    "    5: 1,\n",
    "    6: 0,\n",
    "    7: 1\n",
    "}\n",
    "\n",
    "team_1_remap = {\n",
    "    0: 0,\n",
    "    1: 0,\n",
    "    2: 1,\n",
    "    3: 0,\n",
    "    4: 1,\n",
    "    5: 0,\n",
    "    6: 1,\n",
    "    7: 1\n",
    "}\n",
    "objects_per_image = pd.read_pickle(data/\"objects_per_image_oversampled.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a2c9ef7-e8f0-4bf7-bb2f-1b4f39ae6bf9",
   "metadata": {
    "id": "1a2c9ef7-e8f0-4bf7-bb2f-1b4f39ae6bf9"
   },
   "outputs": [],
   "source": [
    "def class_mapping(ball_count, team_0_count, team_1_count):\n",
    "    '''\n",
    "    Assigns each row in the objects_per_image DataFrame to a class based on object counts.\n",
    "    '''\n",
    "    if (ball_count == 0) & (team_0_count == 0) & (team_1_count == 0):\n",
    "        return 0\n",
    "    elif (ball_count == 0) & (team_0_count > 0) & (team_1_count == 0):\n",
    "        return 1\n",
    "    elif (ball_count == 0) & (team_0_count == 0) & (team_1_count > 0):\n",
    "        return 2\n",
    "    elif (ball_count > 0) & (team_0_count == 0) & (team_1_count == 0):\n",
    "        return 3\n",
    "    elif (ball_count == 0) & (team_0_count > 0) & (team_1_count > 0):\n",
    "        return 4\n",
    "    elif (ball_count > 0) & (team_0_count > 0) & (team_1_count == 0):\n",
    "        return 5\n",
    "    elif (ball_count > 0) & (team_0_count == 0) & (team_1_count > 0):\n",
    "        return 6\n",
    "    else:\n",
    "        return 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c973fed7-10ad-4d7c-a73e-e791abd279cc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "c973fed7-10ad-4d7c-a73e-e791abd279cc",
    "outputId": "13a76718-5f83-4269-d9c4-ad9e75b4b8c6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>class</th>\n",
       "      <th>image_name</th>\n",
       "      <th>img_ball_count</th>\n",
       "      <th>img_team_0_count</th>\n",
       "      <th>img_team_1_count</th>\n",
       "      <th>class</th>\n",
       "      <th>multiclass</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23905</th>\n",
       "      <td>top_view_31511.png</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17885</th>\n",
       "      <td>top_view_26094.png</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84829</th>\n",
       "      <td>wide_view_38446.png</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57622</th>\n",
       "      <td>wide_view_1396.png</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88127</th>\n",
       "      <td>wide_view_41413.png</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "class           image_name  img_ball_count  img_team_0_count  \\\n",
       "23905   top_view_31511.png               1                 4   \n",
       "17885   top_view_26094.png               1                 2   \n",
       "84829  wide_view_38446.png               1                 5   \n",
       "57622   wide_view_1396.png               1                 9   \n",
       "88127  wide_view_41413.png               0                 0   \n",
       "\n",
       "class  img_team_1_count  class  multiclass  \n",
       "23905                 4      7           7  \n",
       "17885                 2      7           7  \n",
       "84829                 2      7           7  \n",
       "57622                 9      7           7  \n",
       "88127                 1      2           2  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "objects_per_image['class'] = objects_per_image[\n",
    "    ['img_ball_count', 'img_team_0_count', 'img_team_1_count']\n",
    "].apply(lambda x: class_mapping(x.img_ball_count, x.img_team_0_count, x.img_team_1_count), axis=1)\n",
    "\n",
    "objects_per_image['multiclass'] = objects_per_image['class']\n",
    "\n",
    "objects_per_image.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bw5JiKA2GlIr",
   "metadata": {
    "id": "bw5JiKA2GlIr"
   },
   "outputs": [],
   "source": [
    "# Adapted T. Majidzadeh's HW 10 submission, with some edits for the use case.\n",
    "\n",
    "def load_data(image_paths, labels, splits):\n",
    "    \"\"\" Load and split data into train, validation and test sets\n",
    "\n",
    "    Params:\n",
    "    -------\n",
    "    image_paths (np.ndarray): Paths to load images.\n",
    "    labels (np.ndarray): Labels of shape (N,)\n",
    "    splits (tuple): 3 values summing to 1 defining split of train, validation and test sets\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    X_train (np.ndarray): Train images of shape (N_train, 100, 100)\n",
    "    y_train (np.ndarray): Train labels of shape (N_train,)\n",
    "    X_val (np.ndarray): Val images of shape (N_val, 100, 100)\n",
    "    y_val (np.ndarray): Val labels of shape (N_val,)\n",
    "    X_test (np.ndarray): Test images of shape (N_test, 100, 100)\n",
    "    y_test (np.ndarray): Test labels of shape (N_test,)\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # Data is already shuffled on input.\n",
    "    # create data splits (training, val, and test sets)\n",
    "    train_val_index = int(np.floor(len(labels) * splits[0]))\n",
    "    val_test_index = int(np.floor(len(labels) * (splits[0] + splits[1])))\n",
    "\n",
    "    X_train_paths, y_train = image_paths[0:train_val_index], labels[0:train_val_index]\n",
    "    X_val_paths, y_val = image_paths[train_val_index:val_test_index], labels[train_val_index:val_test_index]\n",
    "    X_test_paths, y_test = image_paths[val_test_index:], labels[val_test_index:]\n",
    "\n",
    "    print(\"Loading train...\")\n",
    "    X_train = [img_to_array(load_img(path, target_size=(100,100))) for path in X_train_paths]\n",
    "    print(\"Loading val...\")\n",
    "    X_val = [img_to_array(load_img(path, target_size=(100,100))) for path in X_val_paths]\n",
    "    print(\"Loading test...\")\n",
    "    X_test = [img_to_array(load_img(path, target_size=(100,100))) for path in X_test_paths]\n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test\n",
    "\n",
    "def preprocess_data(X_train, y_train, X_val, y_val, X_test, y_test):\n",
    "    \"\"\"\n",
    "    Applies augmentations\n",
    "\n",
    "    Params:\n",
    "    -------\n",
    "    X_train (np.ndarray): Train images of shape (N_train, 100, 100)\n",
    "    y_train (np.ndarray): Train labels of shape (N_train,)\n",
    "    X_val (np.ndarray): Val images of shape (N_val, 100, 100)\n",
    "    y_val (np.ndarray): Val labels of shape (N_val,)\n",
    "    X_test (np.ndarray): Test images of shape (N_test, 100, 100)\n",
    "    y_test (np.ndarray): Test labels of shape (N_test,)\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    Augmented & Rescaled Values for X_train\n",
    "    \"\"\"\n",
    "    # image augmentation (random flip) on training data\n",
    "    print(\"Augmenting: Left-right flip\")\n",
    "    X_train = tf.image.flip_left_right(X_train)\n",
    "    print(\"Augmenting: Hue\")\n",
    "    X_train = tf.image.stateless_random_hue(X_train, .0075, (298996, 815818))\n",
    "    print(\"Augmenting: Saturation\")\n",
    "    X_train = tf.image.stateless_random_saturation(X_train, 0, .7, (857174, 135799))\n",
    "    print(\"Augmenting: Brightness\")\n",
    "    X_train = tf.image.stateless_random_brightness(X_train, .4, (153696, 274697))\n",
    "\n",
    "    # shuffle X_train and y_train, i.e., shuffle two tensors in the same order\n",
    "    print(\"Shuffling...\")\n",
    "    shuffle = tf.random.shuffle(tf.range(tf.shape(X_train)[0], dtype=tf.int32))\n",
    "    X_train = tf.gather(X_train, shuffle).numpy() # transform X back to numpy array instead of tensor\n",
    "    y_train = tf.gather(y_train, shuffle).numpy() # transform y back to numpy array instead of tensor\n",
    "\n",
    "    # rescale training, val, and test images by dividing each pixel by 255.0\n",
    "    print(\"Rescaling and Squeezing...\")\n",
    "    X_train, X_val, X_test = np.squeeze(np.array(X_train)), np.squeeze(np.array(X_val)), np.squeeze(np.array(X_test))\n",
    "    X_train, X_val, X_test = X_train / 255, X_val / 255, X_test / 255\n",
    "\n",
    "    print(\"Done!\")\n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "571ad573-d34e-4a48-b66c-3560d68c7d8f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "571ad573-d34e-4a48-b66c-3560d68c7d8f",
    "outputId": "e4afffb1-0b8c-4e6b-ab99-b9143f9292ed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading train...\n",
      "Loading val...\n",
      "Loading test...\n"
     ]
    }
   ],
   "source": [
    "# 2. Load the images and match to labels. Format as NumPy arrays.\n",
    "paths = np.array([data/\"images\"/name for name in objects_per_image['image_name']])\n",
    "labels = np.array(objects_per_image['multiclass'])\n",
    "splits = (0.8, 0.1, 0.1)\n",
    "X_train, multiclass_train, X_val, multiclass_val, X_test, multiclass_test = load_data(paths, labels, splits)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "162bedd7-7242-404c-83e9-7ac345c04b69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmenting: Left-right flip\n",
      "Augmenting: Hue\n",
      "Augmenting: Saturation\n",
      "Augmenting: Brightness\n",
      "Shuffling...\n",
      "Rescaling and Squeezing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "X_train, multiclass_train, X_val, multiclass_val, X_test, multiclass_test = preprocess_data(X_train, multiclass_train, X_val, multiclass_val, X_test, multiclass_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6bfdc70e-5db4-4d92-a2c6-2d28b6d076f5",
   "metadata": {
    "id": "6bfdc70e-5db4-4d92-a2c6-2d28b6d076f5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8320,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ball_binary_train, ball_binary_val, ball_binary_test = np.vectorize(ball_remap.get)(multiclass_train), np.vectorize(ball_remap.get)(multiclass_val), np.vectorize(ball_remap.get)(multiclass_test)\n",
    "ball_binary_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f81f4aaf-fb4c-4ff4-b20e-8028b2e3c977",
   "metadata": {
    "id": "f81f4aaf-fb4c-4ff4-b20e-8028b2e3c977"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8320,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "team_0_binary_train, team_0_binary_val, team_0_binary_test = np.vectorize(team_0_remap.get)(multiclass_train), np.vectorize(team_0_remap.get)(multiclass_val), np.vectorize(team_0_remap.get)(multiclass_test)\n",
    "team_0_binary_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c0b0b120-8ff6-4cf5-a6e4-5a548f1c8c8c",
   "metadata": {
    "id": "c0b0b120-8ff6-4cf5-a6e4-5a548f1c8c8c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8320,)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "team_1_binary_train, team_1_binary_val, team_1_binary_test = np.vectorize(team_1_remap.get)(multiclass_train), np.vectorize(team_1_remap.get)(multiclass_val), np.vectorize(team_1_remap.get)(multiclass_test)\n",
    "team_1_binary_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "55e76cf4-3281-46b3-b74e-e6c8ba2ec1a4",
   "metadata": {
    "id": "55e76cf4-3281-46b3-b74e-e6c8ba2ec1a4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8320, 100, 100, 3)\n",
      "(8320,)\n",
      "(1040, 100, 100, 3)\n",
      "(1040,)\n",
      "(1040, 100, 100, 3)\n",
      "(1040,)\n"
     ]
    }
   ],
   "source": [
    "for object in [X_train, multiclass_train, X_val, multiclass_val, X_test, multiclass_test]:\n",
    "    print(object.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5e3cade1-deed-4e53-8131-20ea40b3728c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e41b2248-7bd0-45fb-8986-9882db440432",
   "metadata": {
    "id": "e41b2248-7bd0-45fb-8986-9882db440432"
   },
   "outputs": [],
   "source": [
    "# define an instance of the early_stopping class - from HW 10.\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "  monitor='accuracy',\n",
    "  verbose=1,\n",
    "  patience=4,\n",
    "  mode='max',\n",
    "  restore_best_weights=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "bd532d5a-c0c3-46d7-a2d8-f522d24aeaf1",
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "bd532d5a-c0c3-46d7-a2d8-f522d24aeaf1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv_1 (Conv2D)             (None, 50, 50, 64)        6976      \n",
      "                                                                 \n",
      " conv_2 (Conv2D)             (None, 50, 50, 64)        147520    \n",
      "                                                                 \n",
      " conv_3 (Conv2D)             (None, 50, 50, 64)        65600     \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 25, 25, 64)        0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 25, 25, 64)        0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 40000)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 8)                 320008    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 540104 (2.06 MB)\n",
      "Trainable params: 540104 (2.06 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "234/234 [==============================] - 40s 169ms/step - loss: 6.1501 - accuracy: 0.4372 - val_loss: 1.5739 - val_accuracy: 0.4675\n",
      "Epoch 2/20\n",
      "234/234 [==============================] - 40s 171ms/step - loss: 1.5702 - accuracy: 0.4399 - val_loss: 1.5402 - val_accuracy: 0.4675\n",
      "Epoch 3/20\n",
      "234/234 [==============================] - 40s 171ms/step - loss: 1.5722 - accuracy: 0.4399 - val_loss: 1.5487 - val_accuracy: 0.4675\n",
      "Epoch 4/20\n",
      "234/234 [==============================] - 41s 177ms/step - loss: 1.5625 - accuracy: 0.4399 - val_loss: 1.5367 - val_accuracy: 0.4675\n",
      "Epoch 5/20\n",
      "234/234 [==============================] - 41s 176ms/step - loss: 1.5612 - accuracy: 0.4399 - val_loss: 1.5353 - val_accuracy: 0.4675\n",
      "Epoch 6/20\n",
      "234/234 [==============================] - ETA: 0s - loss: 1.5616 - accuracy: 0.4399Restoring model weights from the end of the best epoch: 2.\n",
      "234/234 [==============================] - 41s 177ms/step - loss: 1.5616 - accuracy: 0.4399 - val_loss: 1.5487 - val_accuracy: 0.4675\n",
      "Epoch 6: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2665a1003a0>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.random.set_seed(33269)\n",
    "np.random.seed(33269)\n",
    "\n",
    "# initialize model\n",
    "multiclass_model = tf.keras.Sequential()\n",
    "\n",
    "# add convolutional layer to model1\n",
    "inputs = tf.keras.layers.Input(shape=(100,100,3))\n",
    "x = tf.keras.layers.Conv2D(\n",
    "    filters = 64,\n",
    "    kernel_size = (6, 6),\n",
    "    strides = (2, 2),\n",
    "    padding = 'same',\n",
    "    data_format = 'channels_last',\n",
    "    name = 'conv_1',\n",
    "    activation = 'relu'\n",
    ")\n",
    "multiclass_model.add(inputs)\n",
    "# Adding additiona complexity via more convolutional layers. The last one takes 2 strides instead of 1.\n",
    "multiclass_model.add(x)\n",
    "x = tf.keras.layers.Conv2D(\n",
    "    filters = 64,\n",
    "    kernel_size = (6, 6),\n",
    "    strides = (1, 1),\n",
    "    padding = 'same',\n",
    "    data_format = 'channels_last',\n",
    "    name = 'conv_2',\n",
    "    activation = 'relu'\n",
    ")\n",
    "\n",
    "multiclass_model.add(x)\n",
    "x = tf.keras.layers.Conv2D(\n",
    "    filters = 64,\n",
    "    kernel_size = (4, 4),\n",
    "    strides = (1, 1),\n",
    "    padding = 'same',\n",
    "    data_format = 'channels_last',\n",
    "    name = 'conv_3',\n",
    "    activation = 'relu'\n",
    ")\n",
    "multiclass_model.add(x)\n",
    "\n",
    "# add max pooling layer to model1\n",
    "x = tf.keras.layers.MaxPooling2D(\n",
    "    pool_size = (2, 2)\n",
    ")\n",
    "multiclass_model.add(x)\n",
    "\n",
    "# add dropout layer to model1\n",
    "x = tf.keras.layers.Dropout(\n",
    "    rate = .2\n",
    ")\n",
    "multiclass_model.add(x)\n",
    "\n",
    "# add a flattening layer to model1\n",
    "x = tf.keras.layers.Flatten()\n",
    "multiclass_model.add(x)\n",
    "\n",
    "# add the classification layer to model1\n",
    "x = layers.Dense(units=8, activation='sigmoid')\n",
    "multiclass_model.add(x)\n",
    "\n",
    "# build and compile model1\n",
    "multiclass_model.build(input_shape=(None, 100, 100, 3))\n",
    "multiclass_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# print model1 summary\n",
    "multiclass_model.summary()\n",
    "\n",
    "# train model1 on (X_train, y_train) data\n",
    "multiclass_model.fit(\n",
    "    X_train,\n",
    "    multiclass_train,\n",
    "    validation_split=0.1,\n",
    "    epochs=20,\n",
    "    callbacks=[early_stopping]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "fbc8d025-4343-4615-94d6-232d28627e40",
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "fbc8d025-4343-4615-94d6-232d28627e40"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33/33 [==============================] - 2s 44ms/step\n"
     ]
    }
   ],
   "source": [
    "multiclass_predictions = np.argmax(multiclass_model.predict(X_test), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "814c5db9-3f12-4f17-8f12-96676610f41a",
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "814c5db9-3f12-4f17-8f12-96676610f41a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:  0.20249999999999999\n",
      "Recall:  0.45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\timot\\anaconda3\\envs\\tf_2_env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "print(\"Precision: \", metrics.precision_score(multiclass_test, multiclass_predictions, average='weighted'))\n",
    "print(\"Recall: \", metrics.recall_score(multiclass_test, multiclass_predictions, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "4018e1b1-01fb-4e9e-a789-a23b6f98a5c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "3b4147ed-76e2-400c-b0cb-d5dd269253e1",
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "3b4147ed-76e2-400c-b0cb-d5dd269253e1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv_1 (Conv2D)             (None, 50, 50, 64)        6976      \n",
      "                                                                 \n",
      " conv_2 (Conv2D)             (None, 50, 50, 64)        147520    \n",
      "                                                                 \n",
      " conv_3 (Conv2D)             (None, 50, 50, 64)        65600     \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 25, 25, 64)        0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 25, 25, 64)        0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 40000)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 40001     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 260097 (1016.00 KB)\n",
      "Trainable params: 260097 (1016.00 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "234/234 [==============================] - 43s 175ms/step - loss: 1.9596 - accuracy: 0.4968 - val_loss: 0.6928 - val_accuracy: 0.5192\n",
      "Epoch 2/20\n",
      "234/234 [==============================] - 44s 186ms/step - loss: 0.6933 - accuracy: 0.5049 - val_loss: 0.6932 - val_accuracy: 0.4808\n",
      "Epoch 3/20\n",
      "234/234 [==============================] - 43s 182ms/step - loss: 0.6934 - accuracy: 0.4948 - val_loss: 0.6933 - val_accuracy: 0.4808\n",
      "Epoch 4/20\n",
      "234/234 [==============================] - 43s 183ms/step - loss: 0.6933 - accuracy: 0.4969 - val_loss: 0.6945 - val_accuracy: 0.4808\n",
      "Epoch 5/20\n",
      "234/234 [==============================] - 43s 183ms/step - loss: 0.6933 - accuracy: 0.4948 - val_loss: 0.6931 - val_accuracy: 0.5192\n",
      "Epoch 6/20\n",
      "234/234 [==============================] - ETA: 0s - loss: 0.6933 - accuracy: 0.5031Restoring model weights from the end of the best epoch: 2.\n",
      "234/234 [==============================] - 43s 183ms/step - loss: 0.6933 - accuracy: 0.5031 - val_loss: 0.6932 - val_accuracy: 0.4808\n",
      "Epoch 6: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2665a355540>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Try applying the model for binary outputs\n",
    "# Start with the ball.\n",
    "tf.random.set_seed(326809)\n",
    "np.random.seed(326809)\n",
    "\n",
    "# initialize model\n",
    "binary_ball_model = tf.keras.Sequential()\n",
    "\n",
    "# add convolutional layer to model1\n",
    "inputs = tf.keras.layers.Input(shape=(100,100,3))\n",
    "x = tf.keras.layers.Conv2D(\n",
    "    filters = 64,\n",
    "    kernel_size = (6, 6),\n",
    "    strides = (2, 2),\n",
    "    padding = 'same',\n",
    "    data_format = 'channels_last',\n",
    "    name = 'conv_1',\n",
    "    activation = 'relu'\n",
    ")\n",
    "binary_ball_model.add(inputs)\n",
    "# Adding additiona complexity via more convolutional layers. The last one takes 2 strides instead of 1.\n",
    "binary_ball_model.add(x)\n",
    "x = tf.keras.layers.Conv2D(\n",
    "    filters = 64,\n",
    "    kernel_size = (6, 6),\n",
    "    strides = (1, 1),\n",
    "    padding = 'same',\n",
    "    data_format = 'channels_last',\n",
    "    name = 'conv_2',\n",
    "    activation = 'relu'\n",
    ")\n",
    "binary_ball_model.add(x)\n",
    "x = tf.keras.layers.Conv2D(\n",
    "    filters = 64,\n",
    "    kernel_size = (4, 4),\n",
    "    strides = (1, 1),\n",
    "    padding = 'same',\n",
    "    data_format = 'channels_last',\n",
    "    name = 'conv_3',\n",
    "    activation = 'relu'\n",
    ")\n",
    "binary_ball_model.add(x)\n",
    "\n",
    "# add max pooling layer to model1\n",
    "x = tf.keras.layers.MaxPooling2D(\n",
    "    pool_size = (2, 2)\n",
    ")\n",
    "binary_ball_model.add(x)\n",
    "\n",
    "# add dropout layer to model1\n",
    "x = tf.keras.layers.Dropout(\n",
    "    rate = .2\n",
    ")\n",
    "binary_ball_model.add(x)\n",
    "\n",
    "# add a flattening layer to model1\n",
    "x = tf.keras.layers.Flatten()\n",
    "binary_ball_model.add(x)\n",
    "\n",
    "# add the classification layer to model1\n",
    "x = layers.Dense(units=1, activation='sigmoid')\n",
    "binary_ball_model.add(x)\n",
    "\n",
    "# build and compile model1\n",
    "binary_ball_model.build(input_shape=(None, 100, 100, 3))\n",
    "binary_ball_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# print model1 summary\n",
    "binary_ball_model.summary()\n",
    "\n",
    "# train model1 on (X_train, y_train) data\n",
    "binary_ball_model.fit(\n",
    "    X_train,\n",
    "    ball_binary_train,\n",
    "    validation_split=0.1,\n",
    "    epochs=20,\n",
    "    callbacks=[early_stopping]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d3fe0190-4b87-492c-972c-0d04b7105880",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33/33 [==============================] - 2s 48ms/step\n"
     ]
    }
   ],
   "source": [
    "ball_binary_predictions = np.round(binary_ball_model.predict(X_test)) # Class threshold of 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "BHrxzpLfS9UM",
   "metadata": {
    "id": "BHrxzpLfS9UM"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:  0.0\n",
      "Recall:  0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\timot\\anaconda3\\envs\\tf_2_env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "print(\"Precision: \", metrics.precision_score(ball_binary_test, ball_binary_predictions, average='binary'))\n",
    "print(\"Recall: \", metrics.recall_score(ball_binary_test, ball_binary_predictions, average='binary'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "h9KOKYpTS_Xt",
   "metadata": {
    "id": "h9KOKYpTS_Xt"
   },
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "Yd4MHB_PTtUt",
   "metadata": {
    "id": "Yd4MHB_PTtUt"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv_1 (Conv2D)             (None, 50, 50, 64)        6976      \n",
      "                                                                 \n",
      " conv_2 (Conv2D)             (None, 50, 50, 64)        147520    \n",
      "                                                                 \n",
      " conv_3 (Conv2D)             (None, 50, 50, 64)        65600     \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 25, 25, 64)        0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 25, 25, 64)        0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 40000)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 40001     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 260097 (1016.00 KB)\n",
      "Trainable params: 260097 (1016.00 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "234/234 [==============================] - 43s 182ms/step - loss: 1.9134 - accuracy: 0.6923 - val_loss: 0.5947 - val_accuracy: 0.7296\n",
      "Epoch 2/20\n",
      "234/234 [==============================] - 43s 183ms/step - loss: 0.6167 - accuracy: 0.6995 - val_loss: 0.5977 - val_accuracy: 0.7296\n",
      "Epoch 3/20\n",
      "234/234 [==============================] - 42s 180ms/step - loss: 0.6140 - accuracy: 0.6995 - val_loss: 0.5928 - val_accuracy: 0.7296\n",
      "Epoch 4/20\n",
      "234/234 [==============================] - 43s 183ms/step - loss: 0.6125 - accuracy: 0.6995 - val_loss: 0.5862 - val_accuracy: 0.7296\n",
      "Epoch 5/20\n",
      "234/234 [==============================] - 42s 181ms/step - loss: 0.6116 - accuracy: 0.6995 - val_loss: 0.5862 - val_accuracy: 0.7296\n",
      "Epoch 6/20\n",
      "234/234 [==============================] - ETA: 0s - loss: 0.6114 - accuracy: 0.6995Restoring model weights from the end of the best epoch: 2.\n",
      "234/234 [==============================] - 42s 181ms/step - loss: 0.6114 - accuracy: 0.6995 - val_loss: 0.5862 - val_accuracy: 0.7296\n",
      "Epoch 6: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2665a036c20>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Team 0.\n",
    "tf.random.set_seed(326809)\n",
    "np.random.seed(326809)\n",
    "\n",
    "# initialize model\n",
    "team_0_model = tf.keras.Sequential()\n",
    "\n",
    "# add convolutional layer to model1\n",
    "inputs = tf.keras.layers.Input(shape=(100,100,3))\n",
    "x = tf.keras.layers.Conv2D(\n",
    "    filters = 64,\n",
    "    kernel_size = (6, 6),\n",
    "    strides = (2, 2),\n",
    "    padding = 'same',\n",
    "    data_format = 'channels_last',\n",
    "    name = 'conv_1',\n",
    "    activation = 'relu'\n",
    ")\n",
    "team_0_model.add(inputs)\n",
    "# Adding additiona complexity via more convolutional layers. The last one takes 2 strides instead of 1.\n",
    "team_0_model.add(x)\n",
    "x = tf.keras.layers.Conv2D(\n",
    "    filters = 64,\n",
    "    kernel_size = (6, 6),\n",
    "    strides = (1, 1),\n",
    "    padding = 'same',\n",
    "    data_format = 'channels_last',\n",
    "    name = 'conv_2',\n",
    "    activation = 'relu'\n",
    ")\n",
    "team_0_model.add(x)\n",
    "x = tf.keras.layers.Conv2D(\n",
    "    filters = 64,\n",
    "    kernel_size = (4, 4),\n",
    "    strides = (1, 1),\n",
    "    padding = 'same',\n",
    "    data_format = 'channels_last',\n",
    "    name = 'conv_3',\n",
    "    activation = 'relu'\n",
    ")\n",
    "team_0_model.add(x)\n",
    "\n",
    "# add max pooling layer to model1\n",
    "x = tf.keras.layers.MaxPooling2D(\n",
    "    pool_size = (2, 2)\n",
    ")\n",
    "team_0_model.add(x)\n",
    "\n",
    "# add dropout layer to model1\n",
    "x = tf.keras.layers.Dropout(\n",
    "    rate = .2\n",
    ")\n",
    "team_0_model.add(x)\n",
    "\n",
    "# add a flattening layer to model1\n",
    "x = tf.keras.layers.Flatten()\n",
    "team_0_model.add(x)\n",
    "\n",
    "# add the classification layer to model1\n",
    "x = layers.Dense(units=1, activation='sigmoid')\n",
    "team_0_model.add(x)\n",
    "\n",
    "# build and compile model1\n",
    "team_0_model.build(input_shape=(None, 100, 100, 3))\n",
    "team_0_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# print model1 summary\n",
    "team_0_model.summary()\n",
    "\n",
    "# train model1 on (X_train, y_train) data\n",
    "team_0_model.fit(\n",
    "    X_train,\n",
    "    team_0_binary_train,\n",
    "    validation_split=0.1,\n",
    "    epochs=20,\n",
    "    callbacks=[early_stopping]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "jp536KgnVFSR",
   "metadata": {
    "id": "jp536KgnVFSR"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33/33 [==============================] - 2s 48ms/step\n"
     ]
    }
   ],
   "source": [
    "team_0_predictions = np.round(team_0_model.predict(X_test)) # Class threshold of 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "V42I5HnGVFp_",
   "metadata": {
    "id": "V42I5HnGVFp_"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:  0.7163461538461539\n",
      "Recall:  1.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Precision: \", metrics.precision_score(team_0_binary_test, team_0_predictions, average='binary'))\n",
    "print(\"Recall: \", metrics.recall_score(team_0_binary_test, team_0_predictions, average='binary'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ef14c5af-13d9-43a0-848b-5320d4c230cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "7evmW4eSTAqX",
   "metadata": {
    "id": "7evmW4eSTAqX"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv_1 (Conv2D)             (None, 50, 50, 64)        6976      \n",
      "                                                                 \n",
      " conv_2 (Conv2D)             (None, 50, 50, 64)        147520    \n",
      "                                                                 \n",
      " conv_3 (Conv2D)             (None, 50, 50, 64)        65600     \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 25, 25, 64)        0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 25, 25, 64)        0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 40000)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 40001     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 260097 (1016.00 KB)\n",
      "Trainable params: 260097 (1016.00 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "234/234 [==============================] - 43s 182ms/step - loss: 1.3577 - accuracy: 0.6955 - val_loss: 0.5943 - val_accuracy: 0.7188\n",
      "Epoch 2/20\n",
      "234/234 [==============================] - 43s 183ms/step - loss: 0.6138 - accuracy: 0.6999 - val_loss: 0.5944 - val_accuracy: 0.7188\n",
      "Epoch 3/20\n",
      "234/234 [==============================] - 42s 181ms/step - loss: 0.6144 - accuracy: 0.6999 - val_loss: 0.5957 - val_accuracy: 0.7188\n",
      "Epoch 4/20\n",
      "234/234 [==============================] - 42s 179ms/step - loss: 0.6112 - accuracy: 0.6999 - val_loss: 0.5949 - val_accuracy: 0.7188\n",
      "Epoch 5/20\n",
      "234/234 [==============================] - 42s 180ms/step - loss: 0.6112 - accuracy: 0.6999 - val_loss: 0.5961 - val_accuracy: 0.7188\n",
      "Epoch 6/20\n",
      "234/234 [==============================] - ETA: 0s - loss: 0.6112 - accuracy: 0.6999Restoring model weights from the end of the best epoch: 2.\n",
      "234/234 [==============================] - 42s 180ms/step - loss: 0.6112 - accuracy: 0.6999 - val_loss: 0.5945 - val_accuracy: 0.7188\n",
      "Epoch 6: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2666e5e9c60>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Team 1.\n",
    "tf.random.set_seed(326809)\n",
    "np.random.seed(326809)\n",
    "\n",
    "# initialize model\n",
    "team_1_model = tf.keras.Sequential()\n",
    "\n",
    "# add convolutional layer to model1\n",
    "inputs = tf.keras.layers.Input(shape=(100,100,3))\n",
    "x = tf.keras.layers.Conv2D(\n",
    "    filters = 64,\n",
    "    kernel_size = (6, 6),\n",
    "    strides = (2, 2),\n",
    "    padding = 'same',\n",
    "    data_format = 'channels_last',\n",
    "    name = 'conv_1',\n",
    "    activation = 'relu'\n",
    ")\n",
    "team_1_model.add(inputs)\n",
    "# Adding additiona complexity via more convolutional layers. The last one takes 2 strides instead of 1.\n",
    "team_1_model.add(x)\n",
    "x = tf.keras.layers.Conv2D(\n",
    "    filters = 64,\n",
    "    kernel_size = (6, 6),\n",
    "    strides = (1, 1),\n",
    "    padding = 'same',\n",
    "    data_format = 'channels_last',\n",
    "    name = 'conv_2',\n",
    "    activation = 'relu'\n",
    ")\n",
    "team_1_model.add(x)\n",
    "x = tf.keras.layers.Conv2D(\n",
    "    filters = 64,\n",
    "    kernel_size = (4, 4),\n",
    "    strides = (1, 1),\n",
    "    padding = 'same',\n",
    "    data_format = 'channels_last',\n",
    "    name = 'conv_3',\n",
    "    activation = 'relu'\n",
    ")\n",
    "team_1_model.add(x)\n",
    "\n",
    "# add max pooling layer to model1\n",
    "x = tf.keras.layers.MaxPooling2D(\n",
    "    pool_size = (2, 2)\n",
    ")\n",
    "team_1_model.add(x)\n",
    "\n",
    "# add dropout layer to model1\n",
    "x = tf.keras.layers.Dropout(\n",
    "    rate = .2\n",
    ")\n",
    "team_1_model.add(x)\n",
    "\n",
    "# add a flattening layer to model1\n",
    "x = tf.keras.layers.Flatten()\n",
    "team_1_model.add(x)\n",
    "\n",
    "# add the classification layer to model1\n",
    "x = layers.Dense(units=1, activation='sigmoid')\n",
    "team_1_model.add(x)\n",
    "\n",
    "# build and compile model1\n",
    "team_1_model.build(input_shape=(None, 100, 100, 3))\n",
    "team_1_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# print model1 summary\n",
    "team_1_model.summary()\n",
    "\n",
    "# train model1 on (X_train, y_train) data\n",
    "team_1_model.fit(\n",
    "    X_train,\n",
    "    team_1_binary_train,\n",
    "    validation_split=0.1,\n",
    "    epochs=20,\n",
    "    callbacks=[early_stopping]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "OI6V_BVvUoB5",
   "metadata": {
    "id": "OI6V_BVvUoB5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33/33 [==============================] - 2s 49ms/step\n"
     ]
    }
   ],
   "source": [
    "team_1_predictions = np.round(team_1_model.predict(X_test)) # Class threshold of 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "gAxhsRuFVY5f",
   "metadata": {
    "id": "gAxhsRuFVY5f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:  0.7221153846153846\n",
      "Recall:  1.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Precision: \", metrics.precision_score(team_1_binary_test, team_1_predictions, average='binary'))\n",
    "print(\"Recall: \", metrics.recall_score(team_1_binary_test, team_1_predictions, average='binary'))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
