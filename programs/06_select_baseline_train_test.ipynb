{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f66c93a0-cad3-4dfb-a0b1-b38146449d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import os\n",
    "import random\n",
    "mids_dir = Path(\"D:\\\\MIDS-W207\")\n",
    "data = mids_dir/\"datasets/soccertrack\"\n",
    "project = mids_dir/\"MIDS-W207-Spring24-Soccer-Detection\"\n",
    "analysis = project/\"analysis\"\n",
    "\n",
    "# Author: Timothy Majidzadeh\n",
    "# Date Created: March 12, 2024\n",
    "# Date Updated: April 13, 2024\n",
    "# Description: From the list of labels, randomly select a subset & split into train/val/test.\n",
    "# Notes: [v1] Created program.\n",
    "#        [v2-v4] Updated baselines for 80/10/10 split. Changed sample size. Re-ran after fixing an issue with the image extraction program.\n",
    "# Inputs: Frame-by-frame labels data.\n",
    "# Outputs: Text files listing the images included in the train/val/test splits for YOLO."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2d07668-064f-46bb-839b-78e0893b4f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def sample_and_split(input_df, batch_size, desired_batches, train_pct=0.8, val_pct=0.1, test_pct=0.1, seed=39305):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "        input_df: The list of images & their labels to sample from, an integer.\n",
    "        batch_size: The number of images intended to process in each batch of the model training, an integer.\n",
    "        train_pct, val_pct, test_pct: The train, val & test percentages, as floats from 0 to 1 adding to 1.\n",
    "    Returns:\n",
    "        train_df, val_df, test_df: The train, val & test data labels.\n",
    "    \"\"\"\n",
    "    to_sample = batch_size * desired_batches\n",
    "    train_val_index = round(to_sample * train_pct)\n",
    "    val_test_index = train_val_index + round(to_sample * val_pct)\n",
    "    sampled_df = input_df.copy().reset_index().sample(n=to_sample, replace=False, random_state=seed)\n",
    "    return sampled_df.iloc[0:train_val_index,], sampled_df.iloc[train_val_index:val_test_index,], sampled_df.iloc[val_test_index:,] \n",
    "\n",
    "\n",
    "def train_val_test_paths(image_paths, set_type, vrsn_num, output_dir=data):\n",
    "    \"\"\"\n",
    "    Create text files which give Ultralytics the paths for the train, val, and test images.\n",
    "    Inputs:\n",
    "        train, val, test: Numpy arrays or lists which are the absolute filepaths.\n",
    "        set_type: 'train', 'val', or 'test', based on the input type.\n",
    "        output_dir: A PathLib Path object.\n",
    "    Outputs:\n",
    "        Saves .txt files with paths to the selected train, val, and test sets.\n",
    "    \"\"\"\n",
    "    output_dir_str = str(output_dir).replace(\"\\\\\", \"/\")\n",
    "    image_paths = list(image_paths.copy().str.replace(\"\\\\\", \"/\").str.replace(str(data).replace(\"\\\\\",\"/\"), \".\"))\n",
    "    with open(output_dir/\"{}_v{}.txt\".format(set_type, str(vrsn_num)), 'w') as f:\n",
    "        i = 0\n",
    "        for image_path in image_paths:\n",
    "            if i == 0:\n",
    "                f.write(image_path)\n",
    "            else:\n",
    "                f.write(\"\\n\"+image_path)\n",
    "            i+=1\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "609ad38a-ddd9-42e1-bf8a-ad20eb18c592",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update to use full dataset when available.\n",
    "top_view_labels = pd.read_pickle(data/\"labels/top_view_labels_stacked/top_view_labels.pkl\")\n",
    "wide_view_labels = pd.read_pickle(data/\"labels/wide_view_labels_stacked/wide_view_labels.pkl\")\n",
    "stacked_labels = pd.concat([top_view_labels, wide_view_labels])\n",
    "labels_filtered = stacked_labels[(stacked_labels['frame_saved'] == True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "65382134-ff8a-469c-89aa-74dd91b1e234",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, val_df, test_df = sample_and_split(labels_filtered, 32, 325)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "88248ddc-b809-4532-b471-38e8ab45edc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "vrsn_num = 4\n",
    "\n",
    "train_paths, val_paths, test_paths = train_df['frame_imgpath'], val_df['frame_imgpath'], test_df['frame_imgpath']\n",
    "for path_list, set_type in zip([train_paths, val_paths, test_paths], ['train', 'val', 'test']):\n",
    "    train_val_test_paths(path_list, set_type, vrsn_num)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
