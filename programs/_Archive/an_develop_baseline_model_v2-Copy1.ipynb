{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6637eaf3-319b-47a2-808e-2c5c1d34ac94",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'warnings' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 14\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtqdm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tqdm\n\u001b[1;32m---> 14\u001b[0m \u001b[43mwarnings\u001b[49m\u001b[38;5;241m.\u001b[39mfilterwarnings(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m, category\u001b[38;5;241m=\u001b[39m\u001b[38;5;167;01mUserWarning\u001b[39;00m) \u001b[38;5;66;03m#used to supress the tf version warning. \u001b[39;00m\n\u001b[0;32m     16\u001b[0m mids_dir \u001b[38;5;241m=\u001b[39m Path(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mD:\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mMIDS-W207\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     17\u001b[0m data \u001b[38;5;241m=\u001b[39m mids_dir\u001b[38;5;241m/\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMIDS-W207-Spring24-Soccer-Detection-Data\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'warnings' is not defined"
     ]
    }
   ],
   "source": [
    "# from moviepy.editor import VideoFileClip\n",
    "from pathlib import Path\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "import tensorflow.compat.v1 as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "import keras_cv\n",
    "import keras\n",
    "\n",
    "from tqdm import tqdm\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning) #used to supress the tf version warning. \n",
    "\n",
    "mids_dir = Path(\"D:\\\\MIDS-W207\")\n",
    "data = mids_dir/\"MIDS-W207-Spring24-Soccer-Detection-Data\"\n",
    "project = mids_dir/\"MIDS-W207-Spring24-Soccer-Detection\"\n",
    "analysis = project/\"analysis\"\n",
    "\n",
    "# Author: Timothy Majidzadeh\n",
    "# Date Created: March 4, 2024\n",
    "# Date Updated: March 5, 2024\n",
    "# Description: Develop the baseline model.\n",
    "# Notes: [v1] Created program.\n",
    "# Inputs: Frame-by-frame image data & labels.\n",
    "# Outputs: Object detection model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae876e8-0999-441b-a776-c85fac5e2f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_img = load_img(data/\"base/top_view/D_20220220_1_0000_0030/D_20220220_1_0000_0030_1.png\")\n",
    "first_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07744794-6b85-4db0-89a2-188a1d85e342",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pd.read_pickle(data/\"base/top_view_labels/top_view_labels.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62550c5c-4a93-4b0a-bcd9-a6152bc85e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_width, target_height = 1280, 736\n",
    "train_pct, val_pct = 0.6, 0.4\n",
    "batch_size = 8\n",
    "learning_rate = 0.001\n",
    "epoch = 5\n",
    "global_clipnorm = 10\n",
    "class_ids = [\n",
    "    \"ball\"\n",
    "]\n",
    "class_mapping = dict(zip(range(len(class_ids)), class_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e0f18f-a307-45f9-9e8a-1698df2c6f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_labels(input_df, target_height, target_width):\n",
    "    resized_labels = input_df.copy()\n",
    "    resized_labels.loc[\n",
    "        : , (slice(None), slice(None), ['bb_width', 'bb_left']\n",
    "    )] = round(resized_labels.loc[: , (slice(None), slice(None), ['bb_width', 'bb_left'])] * target_width / 3840)\n",
    "    resized_labels.loc[\n",
    "        : , (slice(None), slice(None), ['bb_height', 'bb_top'])\n",
    "    ] = round(resized_labels.loc[: , (slice(None), slice(None), ['bb_height', 'bb_top'])] * target_height / 2160)\n",
    "    return resized_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f2061c-9db8-4fc1-a7f7-50ada12e823a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# resized_labels = scale_labels(labels, target_height=target_height, target_width=target_width)\n",
    "resized_labels = labels.copy()\n",
    "resized_filtered_labels = resized_labels[(resized_labels['frame_saved'] == True)]\n",
    "sampled_labels = resized_filtered_labels.sample(frac = 0.005, random_state=507401).reset_index()\n",
    "sampled_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca479b7-ba07-46f6-a0c6-01b23b99aeed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bbs(input_df):\n",
    "    classes = tf.constant([[0] for i in input_df.index])\n",
    "    boxes = tf.constant([\n",
    "        [\n",
    "            [\n",
    "                input_df['ball']['ball']['bb_left'][i], input_df['ball']['ball']['bb_top'][i],\n",
    "                input_df['ball']['ball']['bb_width'][i], input_df['ball']['ball']['bb_height'][i]\n",
    "            ]\n",
    "        ]\n",
    "    for i in input_df.index])\n",
    "    return classes, boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b4491f-4e7a-4cf3-a181-c6f2ce34aeaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes, boxes = get_bbs(sampled_labels)\n",
    "paths = sampled_labels[\"frame_imgpath\"]\n",
    "# images = [img_to_array(load_img(path, target_size=(target_height, target_width))) for path in paths]\n",
    "tf_data = tf.data.Dataset.from_tensor_slices((\n",
    "    tf.constant(paths),\n",
    "    classes,\n",
    "    boxes\n",
    "))\n",
    "tf_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c14667a2-9b8e-4b7d-9efe-1768329980d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classes)\n",
    "print(boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b48412c4-fe5d-4f4c-a461-bfa7c784a454",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the list of sampled images into train, val & test.\n",
    "train_index = int(round(sampled_labels.shape[0] * train_pct))\n",
    "train = tf_data.take(train_index)\n",
    "val = tf_data.skip(train_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d748fd04-f218-4d96-aaea-850d1b43984f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(image_path):\n",
    "    image = tf.io.read_file(image_path)\n",
    "    image = tf.image.decode_png(image, channels=3)\n",
    "    return image\n",
    "\n",
    "def load_dataset(image_path, classes, bbox):\n",
    "    # Read Image\n",
    "    image = load_image(image_path)\n",
    "    bounding_boxes = {\n",
    "        \"classes\": tf.cast(classes, dtype=tf.float32),\n",
    "        \"boxes\": bbox\n",
    "    }\n",
    "    print(bounding_boxes)\n",
    "    return {\"images\": tf.cast(image, tf.float32), \"bounding_boxes\": bounding_boxes}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "027dcf8d-17be-4e46-8950-bd47725b1de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "augmenter = keras.Sequential(\n",
    "    layers=[\n",
    "        keras_cv.layers.Resizing(\n",
    "            height=target_height,\n",
    "            width=target_width,\n",
    "            interpolation=\"bilinear\",\n",
    "            crop_to_aspect_ratio=False,\n",
    "            pad_to_aspect_ratio=True,\n",
    "            bounding_box_format=\"xywh\"\n",
    "        ),\n",
    "        keras_cv.layers.RandomFlip(mode=\"horizontal\", bounding_box_format=\"xywh\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be2a4f9-54d1-47c1-9013-9b4807060070",
   "metadata": {},
   "outputs": [],
   "source": [
    "resizing = keras_cv.layers.Resizing(\n",
    "    height=target_height,\n",
    "    width=target_width,\n",
    "    interpolation=\"bilinear\",\n",
    "    crop_to_aspect_ratio=False,\n",
    "    pad_to_aspect_ratio=True,\n",
    "    bounding_box_format=\"xywh\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d28ae0ad-982a-44f2-9c83-4a7a36902690",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val = train.map(load_dataset, num_parallel_calls=tf.data.AUTOTUNE), val.map(load_dataset, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "train, val = train.shuffle(batch_size * 4), val.shuffle(batch_size * 4)\n",
    "print(train)\n",
    "train, val = train.ragged_batch(batch_size, drop_remainder=True), val.ragged_batch(batch_size, drop_remainder=True)\n",
    "print(train)\n",
    "train = train.map(augmenter, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "val = val.map(resizing, num_parallel_calls=tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a578cdb-faef-4759-9856-bcb80d425263",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict_to_tuple(inputs):\n",
    "    return inputs[\"images\"], inputs[\"bounding_boxes\"]\n",
    "\n",
    "# train_as_tuple, val_as_tuple = train.map(dict_to_tuple), val.map(dict_to_tuple)\n",
    "# train, val = train.prefetch(tf.data.AUTOTUNE), val.prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d5002ed-54e4-43bc-b610-9752929bbf63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the model!\n",
    "optimizer = keras.optimizers.Adam(\n",
    "    learning_rate=learning_rate, global_clipnorm=global_clipnorm\n",
    ")\n",
    "backbone = keras_cv.models.YOLOV8Backbone.from_preset(\n",
    "    \"yolo_v8_s_backbone\"\n",
    ")\n",
    "model = keras_cv.models.YOLOV8Detector(\n",
    "    backbone=backbone,\n",
    "    num_classes=len(class_mapping),\n",
    "    bounding_box_format=\"xywh\",\n",
    "    fpn_depth=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c5755e9-219c-4f3a-88fb-da513df370b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "coco_metrics_callback = keras_cv.callbacks.PyCOCOCallback(\n",
    "    val, bounding_box_format=\"xywh\"\n",
    ")\n",
    "model.compile(\n",
    "    classification_loss=\"binary_crossentropy\",\n",
    "    box_loss=\"ciou\",\n",
    "    optimizer=optimizer\n",
    ")\n",
    "model.fit(\n",
    "    train,\n",
    "    validation_data=val,\n",
    "    epochs=epoch\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e580e2fe-b77b-409f-8e97-786a1b2c29ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c04ff61-440f-420a-8586-25bd9fbd486e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(project/\"analysis/Yolov8/YOLOv8_Baseline_v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07878416-edcc-4e9a-ba37-762dfd39951b",
   "metadata": {},
   "outputs": [],
   "source": [
    "val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c83ef8e9-9bb9-473c-9183-0c0307d98b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(val)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
